# ğŸ§  Contextual Passage-Based Question Answering System

A powerful, user-friendly web application built with **Streamlit** that answers questions based on user-uploaded or pasted passages. This system uses a modular NLP architecture with contextual memory, chunked embeddings, and semantic search â€” ideal for educational tools, customer support, document assistants, and more.

---

## ğŸš€ Features

- ğŸ” Login / Signup Authentication
- ğŸ“„ Upload or paste context passages (`.txt`)
- ğŸ§± Modular NLP pipeline
- ğŸ§  Chat memory (per user session)
- ğŸ” Chunked semantic retrieval using embeddings
- ğŸ¤– Answers from best-matching passage chunk
- ğŸ§¼ Clear session and logout functionality
- ğŸ§‘â€ğŸ’» Simple, clean Streamlit interface

---

## ğŸ“ Project Structure

```

contextual-qa-app/
â”œâ”€â”€ main.py                     # Streamlit app entry point
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ auth.py                 # Login / Signup management
â”‚   â”œâ”€â”€ chunker.py              # Text chunking logic
â”‚   â”œâ”€â”€ embedder.py             # Sentence embedding using SBERT
â”‚   â”œâ”€â”€ retriever.py            # Retrieve best matching chunk
â”‚   â”œâ”€â”€ answerer.py             # Extracts answer from text
â”‚   â”œâ”€â”€ memory.py               # Chat memory (Q\&A history)
|â”€â”€ users.json                  #user database(Created on first use)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                   # Project README (you are here)

````

---

## âš™ï¸ Installation

### 1. Clone this repository

```bash
git clone https://github.com/Omer-443/Passage_Q-A_NLP.git
cd Passage_Q-A_NLP
````

### 2. (Optional) Create and activate a virtual environment

```bash
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

Or manually install essentials:

```bash
pip install streamlit torch sentence-transformers bcrypt
```

---

## â–¶ï¸ Running the App

Start the Streamlit app:

```bash
streamlit run main.py
```

## ğŸ§  How It Works

1. **Login or Sign Up** (User authentication handled in `auth.py`)
2. **Paste or Upload** a text passage
3. The passage is **chunked** into small sections
4. Each chunk is **embedded** into a semantic vector using `sentence-transformers`
5. On user question:

   * The question is embedded
   * Similarity is computed to find the best-matching chunk
6. The **best chunk** is passed to the **answer generator**
7. The **answer is displayed** with optional context view
8. The interaction is **saved to memory** for the session

---

## ğŸ§  Chat Memory

* Stores recent questions and answers
* Displayed in the sidebar
* Memory resets if session is cleared or restarted

---

## ğŸ” Authentication

* New users can sign up securely
* Passwords are hashed with bcrypt
* User data is stored in `data/users.db`
* Includes login/logout functionality

---

## ğŸ“¦ Sample `.txt` Inputs

Try passages from:

* News articles
* Wikipedia excerpts
* PDFs or lecture notes converted to `.txt`
* Custom study material

---

## ğŸ“¦ Requirements

### `requirements.txt`

```
streamlit>=1.25
torch
sentence-transformers
bcrypt
```

---

## ğŸ“ License

This project is licensed under the **MIT License**.
Feel free to use, modify, and share!

---

## ğŸ“Œ Future Improvements

* Add per-user persistent memory (file/DB)
* Token limit slider for better chunking control
* Support for PDF and DOCX files
* Use LLMs for more advanced answering
* Multilingual support
* Streamlit Cloud or Hugging Face Spaces deployment

---

## ğŸ™‹â€â™‚ï¸ Author

**Your Name**
ğŸ“§ [omerfaisal701@gmail.com](mailto:omerfaisal701@gmail.com)
ğŸŒ GitHub: [@Omer-443](https://github.com/Omer-443)

---

## ğŸ“ Contact

Have feedback or questions?
Open an issue or email me â€” happy to help!


